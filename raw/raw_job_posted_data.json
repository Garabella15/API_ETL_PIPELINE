{"status": "OK", "request_id": "a01578bc-8a86-4ad0-a31b-a15e72cb355d", "parameters": {"query": "data engineer and data analyst in uk and usa", "page": 1, "num_pages": 1}, "data": [{"employer_name": "RemoteWorker UK", "employer_logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPmX_kOxfDz-v8rWg03-lIv68NbkYv-jMGKeOY&s=0", "employer_website": null, "employer_company_type": null, "job_publisher": "LinkedIn", "job_id": "-RisfEv8VR8AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Junior SQL Data Engineer Data Platform Engineering \u00b7 CDP Worldwide - London \u00b7 Hybrid Remote", "job_apply_link": "https://uk.linkedin.com/jobs/view/junior-sql-data-engineer-data-platform-engineering-%C2%B7-cdp-worldwide-london-%C2%B7-hybrid-remote-at-remoteworker-uk-3640420233", "job_apply_is_direct": false, "job_apply_quality_score": 0.5584, "job_description": "Purpose and Background Are you a capable SQL data engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL data engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform. This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. They will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, and implement data pipelines to connect operational systems, data for analytics and BI systems. The post holder will provide clean, usable data to the business through the data platform in accordance with governance and execute and evaluate data requirements to support business activities and projects. The post holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP. About CDP: CDP is a not-for-profit charity that runs the global disclosure system for investors, companies, cities, states and regions to manage their environmental impacts. The world\u2019s economy looks to CDP as the gold standard of environmental reporting with the richest and most comprehensive dataset on corporate and city action. In 2021 we launched our new five-year strategy: Accelerating the Rate of Change - find out more here\n\u2022 Visit https://cdp.net/en or follow us CDP to find out more. The Data Engineering Team\u2019s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets\u2019 value and enhance accessibility for CDP\u2019s stakeholders. The team produces value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner. Key responsibilities include: Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools. Implementing data flows to connect operational systems, data for analytics and BI systems. Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently. In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards. Required skills and experience: 3 years Strong technical process understanding regardless of technology. Core SQL Competencies \u2013 SSMS, SSIS, T-SQL, Stored Procedures. High attention to detail. Structured problem-solving techniques. Performance-tuning skills Efficient in building ETL and ELT processes for enterprise solutions Strong software delivery methods and knowledge Desired skills and experience Digital delivery \u2013 has a track record of working on DevOps delivery Exposure in Climate Change data legislation, practices and stakeholders Experience in Environmental related industries i.e Water, Energy and Forestry related This is a permanent full-time role, reporting to the Head of Data Engineering, Salary and benefits: \u00a348,000 - \u00a353,000 per annum, 30 days holiday plus bank holidays. Generous non-contributory pension provision, annual discretionary bonus (depending on company performance), Employee Assistance Program, life assurance, Training and development, Flexible working opportunities and others. Interested applicants must be eligible to work legally in the United Kingdom. We cannot sponsor this role. Before you apply We\u2019ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice\n\u2022 By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes. How to apply Please upload your CV in the application form along with a covering letter as an additional document setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages. The deadline is 11pm 17th February 2023\n\u2022 CDP have regional offices and local partners spanning 50 countries. There are now companies, cities, states and regions from over 90 countries disclosing through CDP on an annual basis. Loading application form Already working at CDP Worldwide? Let\u2019s recruit together and find your next colleague.", "job_is_remote": true, "job_posted_at_timestamp": 1687217097, "job_posted_at_datetime_utc": "2023-06-19T23:24:57.000Z", "job_city": "London", "job_state": null, "job_country": "GB", "job_latitude": 51.507217, "job_longitude": -0.1275862, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=-RisfEv8VR8AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-19T23:25:05.000Z", "job_offer_expiration_timestamp": 1689809105, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": true, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Engineering", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Direct Line Group", "employer_logo": "https://upload.wikimedia.org/wikipedia/en/thumb/3/3c/Direct_Line_Group_logo.svg/800px-Direct_Line_Group_logo.svg.png", "employer_website": "http://www.directlinegroup.com", "employer_company_type": "Finance", "job_publisher": "Direct Line Group Careers", "job_id": "qP3ni6PwqL4AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://www.directlinegroupcareers.com/job/london/data-engineer/38736/49327726448", "job_apply_is_direct": false, "job_apply_quality_score": 0.8967, "job_description": "About us\n\nDirect Line Group is one of the UK's largest insurance companies and home to some of the best-known brands including Direct Line, Churchill and Green Flag.\n\nWhat you'll do:\n\u2022 Work as part of the Data Engineering team to uphold and evolve common standards and collaborate to ensure that our data solutions are complementary and not duplicative.\n\u2022 Build and maintain automated pipelines to support data solutions across BI and analytics use cases.\n\u2022 Collaborate with other technology teams to ingest, transform and load data from multiple data sources, structured and unstructured data.\n\u2022 Work closely with data scientists and data analysts to implement and produce data models.\n\u2022 Build patterns, common ways of working, and standardized data pipelines for DLG to ensure consistency across the organization.\n\nWhat you'll need:\n\nDirect Line Group is going through an exciting transformation to be the top tier data-driven business in the UK's general insurance market.\n\nTo achieve this, we are growing our Data Chapter which is working with the business to build a new large-scale, cloud hosted, secure, and consolidated data and analytics platform to allow our users to work with all their data from a single trusted platform.\n\nThe platform uses the economics of big data, cloud elasticity, Machine Learning (ML)/Artificial Intelligence (AI) automation and permissioned data sharing to turn information into business insights and address business and operational challenges.\n\nOur Data/Platform engineers are accountable for the development and operations of the Data Platform to get maximum value from data for our users.\n\nConcerning the Tech Stack, there are many technologies that make us tick, some of which include; AWS S3, Redshift, SQL, Python, PySpark, and any more.\n\nAs part of the Data Chapter, you will work under the direction of a Chapter Area Lead\n\nWays of Working\n\nHere at Direct Line Group, we recognise the importance of flexibility, not only in our personal lives but also in the way we work. Our mixed model way of working offers a 'best of both worlds' approach combining the best parts of home and office-working, offering flexibility for everyone.\n\nHow much you'll be in the office depends on your role, and we'll consider the flexible working options that work best for you. You can find out more about our flexible working approach or please get in touch with the team to discuss.\n\nBenefits\n\nWe recognise we wouldn't be where we are today without our colleagues, that's why we offer such excellent benefits designed to suit you as and when you need them:\n\u2022 Pension\n\u2022 50% off home, motor and pet insurance plus free travel insurance and Green Flag breakdown cover\n\u2022 Additional optional Health and Dental insurance\n\nLife at Direct Line Group\n\nDirect Line Group is an equal opportunity employer. We value diversity and we're committed to making DLG a truly inclusive place to work.\n\nWe recognise and embrace that people work in different ways and we'll always adapt as much as possible so you have the best and most comfortable working environment that we can offer. We know you're more than a CV, and the things that make you, you, can bring real potential to DLG.\n\nIf you need us to make any adjustments to our recruitment process, speak to our recruitment team who will be happy to support you.\n\n#LI-Hybrid\n\n#LI-CG1", "job_is_remote": false, "job_posted_at_timestamp": 1684886400, "job_posted_at_datetime_utc": "2023-05-24T00:00:00.000Z", "job_city": "London", "job_state": null, "job_country": "GB", "job_latitude": 51.507217, "job_longitude": -0.1275862, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=qP3ni6PwqL4AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": false, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "524113", "job_naics_name": "Direct Life Insurance Carriers"}, {"employer_name": "NatWest Group", "employer_logo": "https://www.natwestgroup.com/content/dam/natwestgroup_com/natwestgroup/images/brand-logos/445x275/image.dim.180.NWG-natwest-group-logo-tile-445x275.jpg", "employer_website": "http://www.rbs.com", "employer_company_type": "Finance", "job_publisher": "NatWest Group Careers", "job_id": "GYIouqnlm3kAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://jobs.natwestgroup.com/jobs/12130048-data-engineer", "job_apply_is_direct": false, "job_apply_quality_score": 0.9107, "job_description": "Join us as a Data Engineer\n\u2022 We\u2019ll look to you to drive the build of effortless, digital-first customer experiences as you simplify our bank while keeping our data safe and secure\n\u2022 Day-to-day, you\u2019ll develop innovative, data-driven solutions through data pipeline modelling and ETL design, inspiring to be commercially successful through insights\n\u2022 This is your opportunity to explore your leadership potential while bringing a competitive edge to your career profile by solving problems and creating smarter solutions\n\u2022 This is a remote hybrid role. You will be expected to be able to travel to a hub office location once a week\n\nWhat you\u2019ll do\n\nIn this role, you\u2019ll develop and share knowledge of business data structures and metrics, advocating for changes when needed for product development. You\u2019ll also educate and embed new data techniques into the business through role modelling, training, and experiment design oversight.\n\nWe\u2019ll look to you to own the end-to-end high-level solution design for a project, programme or initiative, and translate requirements into a series of transition state designs and an executable roadmap. You'll be working closely with the sponsors, key stakeholders, the business and change and functional delivery teams of the project or initiative to ensure design compliance and successful delivery.\n\nYou\u2019ll also be responsible for:\n\u2022 Driving DevOps adoption into the delivery of data engineering, proactively performing root cause analysis while resolving issues\n\u2022 Delivering a clear understanding of data platform cost levers to meet department cost savings and income targets\n\u2022 Driving customer value by understanding complex business problems and requirements to correctly apply the most appropriate and reusable tools to gather and build data solutions\n\u2022 Driving data engineering strategies to build complex, scalable data architecture and a customer feature rich dataset\n\u2022 Working alongside colleagues, scrums and project teams while liaising with technology and engineering teams to build business stakeholder engagement and to develop data solutions\n\u2022 Driving the advanced automation of data engineering pipelines through the removal of manual stages\n\nThe skills you\u2019ll need\n\nWe\u2019re looking for someone with strong communication skills and the ability to proactively engage and manage a wide range of stakeholders. You\u2019ll have extensive experience working in a governed, and regulatory environment, as well as experience of conceptual, logical and physical data modelling in RDBMS, and conceptual, operational modelling in document stores.\n\nIn addition, you'll need experience of data warehouse, ETL, big data and NoSQL architectures and design patterns along with DevOps methodologies. You'll also bring experience of various data ingest methods, including streaming with real time ingestion and exposure to cloud engineering in AWS.\n\nYou\u2019ll also need:\n\u2022 Experience with DEI (BDM), IDMC along with Mongo, Snowflake and AWS S3 data stores\n\u2022 Familiarity with cloud engineering and a good knowledge of AWS Infrastructure architecture including EMRs\n\u2022 Experience of Agile methodologies and the ability to co-ordinate with various workstreams and product owners", "job_is_remote": false, "job_posted_at_timestamp": 1686873600, "job_posted_at_datetime_utc": "2023-06-16T00:00:00.000Z", "job_city": "Edinburgh", "job_state": null, "job_country": "GB", "job_latitude": 55.95325, "job_longitude": -3.188267, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=GYIouqnlm3kAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-06-30T00:00:00.000Z", "job_offer_expiration_timestamp": 1688083200, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "523920", "job_naics_name": "Portfolio Management"}, {"employer_name": "Mars", "employer_logo": "https://www.mars.com/themes/custom/mars_regeneration/logo.svg", "employer_website": "http://www.mars.com", "employer_company_type": "Retail", "job_publisher": "Careers At Mars - Mars, Incorporated", "job_id": "n7NXT9gY590AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "One Demand Data Analytics (ODDA) DevOps Engineer", "job_apply_link": "https://careers.mars.com/global/en/job/R18695/One-Demand-Data-Analytics-ODDA-DevOps-Engineer", "job_apply_is_direct": false, "job_apply_quality_score": 0.9146, "job_description": "One Demand Data & Analytics (ODDA) is a Mars Wrigley program that harnesses the power of data and insights to solve some of the critical business-wide problems we face \u2013 unlocking quality growth and operational excellence.\n\nThrough ODDA, we deliver connected insights across the entire demand ecosystem. We empower our Associates with the right data, tools and capabilities so they can take decisive action, maximizing value and making a meaningful impact on our consumers, our customers and our business.\n\nThe ODDA DevOps Engineer builds software functionality and participates with the delivery team in taking on development responsibilities for the entire tech stack\n\nWhat are we looking for?\n\u2022 Master\u2019s Degree in Computer Science, Application Programming, Software Development, Information Systems, Database Administration, Mathematics, Engineering, or other related field.\n\u2022 6+ years in a rapid development environment, preferably within an analytics environment\n\u2022 Demonstrated ability to be work with internal (Operations) and external (IT) stakeholders\n\u2022 Must be able to interact and collaborate at all levels within Operations Analysis & Performance, OCC, cross-divisional working groups, and outside entities\n\u2022 Experience with increasing code quality and implementing best practices across teams\n\u2022 Advanced technical skills in the following areas:\n\u2022 Proficiency in SQL (CTE, window functions, temporal data), SAP HANA experience is a large plus\n\u2022 Proficiency in a scripting language (Python preferred)\n\u2022 Proficiency of API Consumption\n\u2022 Proficiency in ETL tooling (such as Informatica)\n\u2022 Proven expertise in SAP ECC and SAP APO is a big plus\n\u2022 Excellent communication skills and ability to present concepts to non-technical audience\n\u2022 Must be able to interact and collaborate at all levels within Operations Analysis & Performance, OCC, cross-divisional working groups, and outside entities\n\u2022 Strong project management, organizational, and prioritizations skills\n\u2022 2 to 4 years' experience in applied data science role or equivalent; ideally in a CPG, Retail\n\u2022 Knowledge and experience in modelling techniques and advanced applied skills (e.g. significance testing, GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.) using tools like Spark, Scala, SAS, R, Python, Bayesia, H2O, Storm, Yarn, and Kafka\n\u2022 Experience querying databases (SQL, Hive)\n\u2022 Experience working with big data platforms such as Hadoop ecosystem (Azure), including in-memory solutions (SAP HANA and Apache Spark)\n\u2022 Working knowledge of data visualization tools such as Tableau, Power BI, D3, ggplot, to deliver output to the broader business community to improve decision making and productivity\n\nWhat will be your key responsibilities?\n\u2022 Work closely with Tech Leads and developers of various teams to assess existing problems and to produce process improvement solutions\n\u2022 Detect upcoming bottlenecks and production issues proactively and consult teams hands-on towards improved technical solutions\n\u2022 Participate in planning delivery time, code quality, and process efficiency improvement projects\n\u2022 Execute on plan by building coding standardizations and automating processes for the organization\n\u2022 Perform daily tasks such as environmental health checks, disk space monitoring, and environmental status reports\n\u2022 Maintain and grows knowledge of platform configuration management and troubleshooting\n\u2022 Actively participate in deploying application artifacts to appropriate target environments using the supported technologies and infrastructure\n\u2022 Survey developers and technical members of the organization to understand their main pain points in the coding and development process\n\u2022 Collaborate with the rest of DevOps team to deliver consistent and holistic solutions to the organization\n\n#LI-LD1", "job_is_remote": false, "job_posted_at_timestamp": 1647907200, "job_posted_at_datetime_utc": "2022-03-22T00:00:00.000Z", "job_city": "Newark", "job_state": "NJ", "job_country": "US", "job_latitude": 40.735657, "job_longitude": -74.17236, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=n7NXT9gY590AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 24, "experience_mentioned": true, "experience_preferred": true}, "job_required_skills": ["Analytics", "Data Science", "CPG", "DevOps", "Informatica", "Operations Analysis", "ETL", "Operations", "Coding", "Python", "SAP ECC", "etl tooling", "Regression", "api consumption", "SQL", "Platforms", "H2O", "Text Mining", "Application Programming", "API", "Scala", "SAP APO", "big data platforms", "SAS", "Tableau", "Information Systems", "Project Management", "Spark", "Infrastructure", "Engineering", "Cloud Data Engineer", "Big Data Infrastructure Engineer", "Senior Software Engineer & Business Intelligence Developer", "Big Data & Machine Learning Engineer & Consultant", "Big Data Analytics Engineer", "Member of Technical Staff - Data Science & Big Data Analytics", "Data Engineer", "Business Intelligence Development Engineer - DWH & BI Specialisation", "Real-Time Business Intelligence Analyst", "Data & Cloud Developer"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["Master\u2019s Degree in Computer Science, Application Programming, Software Development, Information Systems, Database Administration, Mathematics, Engineering, or other related field", "6+ years in a rapid development environment, preferably within an analytics environment", "Demonstrated ability to be work with internal (Operations) and external (IT) stakeholders", "Must be able to interact and collaborate at all levels within Operations Analysis & Performance, OCC, cross-divisional working groups, and outside entities", "Experience with increasing code quality and implementing best practices across teams", "Advanced technical skills in the following areas:", "Proficiency in SQL (CTE, window functions, temporal data), SAP HANA experience is a large plus", "Proficiency of API Consumption", "Proficiency in ETL tooling (such as Informatica)", "Proven expertise in SAP ECC and SAP APO is a big plus", "Excellent communication skills and ability to present concepts to non-technical audience", "Strong project management, organizational, and prioritizations skills", "2 to 4 years' experience in applied data science role or equivalent; ideally in a CPG, Retail", "Knowledge and experience in modelling techniques and advanced applied skills (e.g. significance testing, GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.) using tools like Spark, Scala, SAS, R, Python, Bayesia, H2O, Storm, Yarn, and Kafka", "Experience querying databases (SQL, Hive)", "Experience working with big data platforms such as Hadoop ecosystem (Azure), including in-memory solutions (SAP HANA and Apache Spark)", "Working knowledge of data visualization tools such as Tableau, Power BI, D3, ggplot, to deliver output to the broader business community to improve decision making and productivity"], "Responsibilities": ["Work closely with Tech Leads and developers of various teams to assess existing problems and to produce process improvement solutions", "Detect upcoming bottlenecks and production issues proactively and consult teams hands-on towards improved technical solutions", "Participate in planning delivery time, code quality, and process efficiency improvement projects", "Execute on plan by building coding standardizations and automating processes for the organization", "Perform daily tasks such as environmental health checks, disk space monitoring, and environmental status reports", "Maintain and grows knowledge of platform configuration management and troubleshooting", "Actively participate in deploying application artifacts to appropriate target environments using the supported technologies and infrastructure", "Survey developers and technical members of the organization to understand their main pain points in the coding and development process", "Collaborate with the rest of DevOps team to deliver consistent and holistic solutions to the organization"]}, "job_job_title": null, "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_occupational_categories": ["Data, Analytics & Insights"], "job_naics_code": "445292", "job_naics_name": "Confectionery and Nut Stores"}, {"employer_name": "Live Nation Entertainment, Inc.", "employer_logo": "https://www.livenationentertainment.com/wp-content/uploads/2019/02/open-graph-logo.png", "employer_website": "http://www.livenationentertainment.com", "employer_company_type": "Advertising", "job_publisher": "Karkidi", "job_id": "INdvzzdMbyAAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Lead Data Engineer", "job_apply_link": "https://www.karkidi.com/job-details/43695-lead-data-engineer-job", "job_apply_is_direct": false, "job_apply_quality_score": 0.46, "job_description": "THE TEAM\n\nYou will be joining a new Data Engineering team to help get the most value out of our real-time data streams with a focus on ensuring genuine fans have the best opportunity to buy tickets.\n\nTHE JOB\n\nWe are seeking a highly skilled Lead Data Engineer to join our team and play a critical role in developing and maintaining our data infrastructure. The ideal candidate will have a deep understanding of data platforms and tools, as well as experience designing and implementing data pipelines and ETL processes.\n\nWHAT YOU WILL BE DOING\n\u2022 Design, implement, and maintain data pipelines and ETL processes that enable real-time data-driven decision-making.\n\u2022 Work closely with the Director of Data Science and cross-functional teams to identify data requirements, define data models, and develop scalable solutions to support our growing data needs.\n\u2022 Build and maintain data warehouses, and other data infrastructure components that ensure data quality, accuracy, and availability.\n\u2022 Continuously monitor and evaluate data infrastructure performance, and identify opportunities for improvement and optimization.\n\u2022 Ensure compliance with data security and privacy policies, and implement appropriate access controls and data governance frameworks.\n\u2022 Collaborate with data scientists, analysts, and other stakeholders to ensure that data infrastructure supports their analytical needs and requirements.\n\nWHAT YOU NEED TO KNOW (or TECHNICAL SKILLS)\n\u2022 Bachelor's or Master's degree in Computer Science, Engineering, or relevant experience. hands-on data science experience Strong knowledge of data platforms and tools, including Hadoop, Spark, SQL, and NoSQL databases.\n\u2022 Experience designing and implementing data pipelines and ETL processes. Good knowledge of ML ops principles and best practices to deploy, monitor and maintain machine learning models in production. Familiarity with Git and MLflow for managing and tracking model versions\n\u2022 Experience with Kafka is a big bonus\n\u2022 Experience with cloud-based data platforms such as AWS or Google Cloud Platform.\n\u2022 Proven track record of running large scale mission critical data infrastructure in production Experience with container technologies (such as Docker) and orchestration technologies (such as Kubernetes)\n\u2022 Experience working in ecommerce or retail industries is a plus.\n\u2022 An understanding of security measures related to ML models ensuring adherence to data privacy regulations.\n\nYOU (BEHAVIOURAL SKILLS)\n\u2022 Excellent problem-solving and analytical skills, with the ability to identify and resolve complex data infrastructure issues.\n\u2022 Proficient collaborating with data scientists to understand their requirements and assist implementation of machine learning models.\n\u2022 A Deep product focused mindset, with a desire to understand your customers and what will make their use of your output easier and more efficient.\n\u2022 Curious by nature, enjoy looking into problems around your core tasks, experimenting with potential solutions.\n\nLIFE AT TICKETMASTER\n\nWe are proud to be a part of Live Nation Entertainment, the world\u2019s largest live entertainment company.\n\nOur vision at Ticketmaster is to connect people around the world to the live events they love. As the world\u2019s largest ticket marketplace and the leading global provider of enterprise tools and services for the live entertainment business, we are uniquely positioned to successfully deliver on that vision.\n\nWe do it all with an intense passion for Live and an inspiring and diverse culture driven by accessible leaders, attentive managers, and enthusiastic teams. If you\u2019re passionate about live entertainment like we are, and you want to work at a company dedicated to helping millions of fans experience it, we want to hear from you.\n\nOur work is guided by our values:\n\nReliability - We understand that fans and clients rely on us to power their live event experiences, and we rely on each other to make it happen.\n\nTeamwork - We believe individual achievement pales in comparison to the level of success that can be achieved by a team\n\nIntegrity - We are committed to the highest moral and ethical standards on behalf of the countless partners and stakeholders we represent\n\nBelonging - We are committed to building a culture in which all people can be their authentic selves, have an equal voice and opportunities to thrive\n\nEQUAL OPPORTUNITIES\n\nWe are passionate and committed to our people and go beyond the rhetoric of diversity and inclusion. You will be working in an inclusive environment and be encouraged to bring your whole self to work. We will do all that we can to help you successfully balance your work and homelife. As a growing business we will encourage you to develop your professional and personal aspirations, enjoy new experiences, and learn from the talented people you will be working with. It's talent that matters to us and we encourage applications from people irrespective of their gender, race, sexual orientation, religion, age, disability status or caring responsibilities.", "job_is_remote": true, "job_posted_at_timestamp": 1686614400, "job_posted_at_datetime_utc": "2023-06-13T00:00:00.000Z", "job_city": null, "job_state": null, "job_country": "GB", "job_latitude": 55.37805, "job_longitude": -3.435973, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=INdvzzdMbyAAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": true}, "job_required_skills": ["SQL"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": 55000, "job_max_salary": 80000, "job_salary_currency": "GBP", "job_salary_period": "YEAR", "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "541810", "job_naics_name": "Advertising Agencies"}, {"employer_name": "Harnham", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Harnham", "job_id": "mBW2boLuUz8AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer", "job_apply_link": "https://www.harnham.com/job/e1aeb1da-8723-4ba1-d23d-08d5948a7341-data-engineer-durham-county-durham/", "job_apply_is_direct": false, "job_apply_quality_score": 0.8198, "job_description": "Data Engineer\n\nRemote\n\nUp to \u00a375, 000\n\nPermanent\n\nAn exciting opportunity for a Data Engineer to join a boutique tech consultancy start-up and help high-profile clients implement disruptive technologies to their businesses.\n\nThe Company\n\nThe company has a very small headcount, and has big expansion plans over the next two years, and work with a number of high profile companies, individuals, and influencers. The initial project will focus on heling a high net-worth individual modernise and optimise the data for their fleet of private jets.\n\nCurrently, this is a standalone role, and will work alongside a permanent Data Scientist. A consultancy has been on board for all data engineering needs, but they will hand over to this role to build out the permanent team.\n\nThe role and responsibilities\n\u2022 Work with CEO and Head of Data to develop a data platform (AWS)\n\u2022 Building upon PoC work that\u2019s already undertaken\n\u2022 Supporting Data Scientist by providing clean data\n\u2022 Optimising for model performance\n\nYour skills and experience\n\u2022 Experience with AWS, Python and Databricks\n\u2022 Experience with APIs\n\u2022 Experience with ML Ops (preferable)\n\u2022 Experience or education in aerospace (preferable)\n\nBenefits\n\u2022 Up to \u00a375, 000 plus discretionary bonus\n\u2022 Private healthcare\n\u2022 Fully remote role", "job_is_remote": false, "job_posted_at_timestamp": 1686046762, "job_posted_at_datetime_utc": "2023-06-06T10:19:22.000Z", "job_city": "Durham", "job_state": null, "job_country": "GB", "job_latitude": 54.77525, "job_longitude": -1.584852, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=mBW2boLuUz8AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-13T23:59:59.000Z", "job_offer_expiration_timestamp": 1689292799, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "Plaid Inc.", "employer_logo": "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Plaid_logo.svg/1200px-Plaid_logo.svg.png", "employer_website": "http://plaid.com", "employer_company_type": null, "job_publisher": "Karkidi", "job_id": "UrXmv5VA3eUAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Engineer - Data Platform", "job_apply_link": "https://www.karkidi.com/job-details/28493-data-engineer-data-platform-job", "job_apply_is_direct": false, "job_apply_quality_score": 0.5586, "job_description": "We believe that the way people interact with their finances will drastically improve in the next few years. We\u2019re dedicated to empowering this transformation by building the tools and experiences that thousands of developers use to create their own products. Plaid powers the tools millions of people rely on to live a healthier financial life. We work with thousands of companies like Venmo, SoFi, several of the Fortune 500, and many of the largest banks to make it easy for people to connect their financial accounts to the apps and services they want to use. Plaid\u2019s network covers 12,000 financial institutions across the US, Canada, UK and Europe. Founded in 2013, the company is headquartered in San Francisco with offices in New York, Salt Lake City, Washington D.C., London and Amsterdam.\n\nMaking data-driven decisions is key to Plaid's culture. To support that, we need to scale our data systems while maintaining correct and complete data. We provide tooling and guidance to teams across engineering, product, and business and help them explore our data quickly and safely to get the data insights they need, which ultimately helps Plaid serve our customers more effectively. In addition, Plaid will not be successful if we can't move quickly. We build the data systems and tools that enable everyone at Plaid to be data-driven, making analytics easy, obvious, and proactive across the company.\n\nData Engineers heavily leverage SQL and Python to build data workflows that integrate with our Golang and Typescript applications. We use tools like DBT, Airflow, Redshift, ElasticSearch, Atlan, and Retool to orchestrate data pipelines and define workflows. We work with engineers, product managers, business intelligence, data analysts, and many other teams to build Plaid's data strategy and a data-first mindset.\n\nOur engineering culture is IC-driven -- we favor bottom-up ideation and empowerment of our incredibly talented team. We are looking for engineers who are motivated by creating impact for our consumers and customers, growing together as a team, shipping the MVP, and leaving things better than we found them.\n\nWhat excites you\n\u2022 Defining the long-term technical roadmap for building a data-drive culture at Plaid\n\u2022 Leading key data engineering projects that drive collaboration across the company\n\u2022 Mentoring engineers, operations, and data analysts on best practices for data organization and query performance\n\u2022 Advocating for adopting industry tools and practices at the right time\n\u2022 Owning core SQL and python data pipelines that power our data lake and data warehouse\n\u2022 Well-documented data with defined dataset quality, uptime, and usefulness.\n\nWhat excites us\n\u2022 2 years of dedicated data engineering experience, solving complex data pipelines issues at scale.\n\u2022 You value SQL as a flexible and extensible tool, and are comfortable with modern SQL data orchestration tools like DBT, Mode, Hightouch, and Airflow.\n\u2022 Experience working both real-time systems like Kinesis, Kafka, Flink, and batch data pipelines in Redshift, Presto, and Data Lakes.\n\u2022 You appreciate the importance of schema design, and can evolve an analytics schema on top of unstructured data.\n\u2022 You are excited to try out new technologies. You like to produce proof-of-concepts that balance technical advancement and user experience and adoption.\n\u2022 You like to get deep in the weeds to manage, deploy, and improve low level data infrastructure.\n\u2022 You are empathetic working with stakeholders. You listen to them, ask the right questions, and collaboratively come up with the best solutions for their needs.\n\u2022 You are a champion for data privacy and integrity, and always act in the best interest of consumers.\n\nPlaid is proud to be an equal opportunity employer and values diversity at our company. We do not discriminate based on race, color, national origin, ethnicity, religion or religious belief, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, military or veteran status, disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state, and local laws. Plaid is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance with your application or interviews due to a disability, please let us know at accommodations@plaid.com.", "job_is_remote": true, "job_posted_at_timestamp": 1671926400, "job_posted_at_datetime_utc": "2022-12-25T00:00:00.000Z", "job_city": "London", "job_state": null, "job_country": "GB", "job_latitude": 51.507217, "job_longitude": -0.1275862, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=UrXmv5VA3eUAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 24, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": ["TensorFlow"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": 65000, "job_max_salary": 95000, "job_salary_currency": "GBP", "job_salary_period": "YEAR", "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}, {"employer_name": "BrightTALK", "employer_logo": "https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/BrightTALK_Logo.png/220px-BrightTALK_Logo.png", "employer_website": "http://www.brighttalk.com", "employer_company_type": "Computer Services", "job_publisher": "Karkidi", "job_id": "X0XwAuDJXRoAAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer UK (Remote)", "job_apply_link": "https://www.karkidi.com/job-details/24318-senior-data-engineer-uk-remote-job", "job_apply_is_direct": false, "job_apply_quality_score": 0.5408, "job_description": "We are looking for a talented and passionate Sr. Data Engineer / Architect to join BrightTALK\u2019s Data team based in the US East coast.The Data team builds and maintains the infrastructure responsible for consuming, exposing and creating product and product-derived (augmented) datasets. This team owns the pipelines that transport and process database data from all of BrightTALK\u2019s product surfaces. The team is responsible for building and operating the infrastructure and services that ensure data accuracy\n\nResponibilities\n\u2022 Building and maintain highly reliable data services to integrate with dozens of consumers.\n\u2022 Creating ETL or ELT pipelines that transform and process structured and unstructured data in real-time.\n\u2022 Designing data models for optimal storage and retrieval to support high latency.\n\u2022 Deploying and monitoring large database clusters that are performant and highly-available.\n\u2022 Working cross-functionally with data scientists, backend engineers, and product managers to design and implement new data models to support the product.\n\u2022 Developing your skills through exceptional training as well as frequent coaching and mentoring from colleagues.\n\u2022 Some upcoming technical challenges include scaling our data ingestion pipelines across a growing number of AWS and data center based data sources, reducing the latency of our product data ingestion pipelines through improving our batch jobs, and extending our data lake architecture for the growing ecosystem of data ingestion and creation tools.\n\nSkils\n\u2022 Bachelor's degree (or equivalent) in Computer Science or related field.\n\u2022 5+ years of experience building real-time and distributed architecture, from whiteboard to production\n\u2022 Strong programming skills in Python, SQL.Versatility.\n\u2022 Experience across the entire spectrum of data engineering, including:\n\u2022 Data stores (e.g., AWS RDS, AWS Athena, AWS Aurora, AWS Redshift).\n\u2022 Data pipeline and workflow orchestration tools (e.g., Azkaban, Airflow).\n\u2022 Data processing technologies (e.g., Spark, Pentaho).\n\u2022 Deployment and monitoring batch and realtime integrating with large database clusters in public cloud platforms.\n\u2022 Adaptable. Goals can change fast. You anticipate and react quickly.\n\u2022 Autonomous. You own what you work on. You move fast and get things done.\n\u2022 Excellent communication. You will need communicate complex ideas effectively to both technical and non-technical audiences, and both verbally and in writing.\n\u2022 Collaborative. You must work collaboratively in a cross-functional team and with people at all levels in an organization.\n\u2022 Industry experience building and productionizing innovative end-to-end Machine Learning systems is a plus.\n\nExpertise/ Qualifications\n\u2022 Strong Knowledge of Python & SQL.\n\u2022 Hands on experience with either Pentaho or other Data Integration tools in the market.\n\u2022 Demonstrable experience of working in a linux environmentUnderstanding of Terraform and use of it for deployment pipelines.\n\u2022 Experience working with CI/CD tools.\n\nWhy we like working at BrightTALK\n\u2022 Friendly, talented, collaborative and entrepreneurial teams.\n\u2022 Generous and comprehensive benefits.\n\u2022 Generous holiday policy with a flexible schedule.\n\u2022 Beautiful London office close to Liverpool Street Station.\n\u2022 Regular company sponsored social events.\n\u2022 Training allowance and opportunities to innovate.\n\u2022 Team building and volunteering opportunities.\n\u2022 Stock options in our business.\n\u2022 We LOVE recognising our people and award trips to our global offices for quarterly program winners.", "job_is_remote": true, "job_posted_at_timestamp": 1653955200, "job_posted_at_datetime_utc": "2022-05-31T00:00:00.000Z", "job_city": null, "job_state": null, "job_country": "GB", "job_latitude": 55.37805, "job_longitude": -3.435973, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=X0XwAuDJXRoAAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 60, "experience_mentioned": true, "experience_preferred": true}, "job_required_skills": ["Python Programming"], "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": 65000, "job_max_salary": 95000, "job_salary_currency": "GBP", "job_salary_period": "YEAR", "job_highlights": {}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "541511", "job_naics_name": "Custom Computer Programming Services"}, {"employer_name": "Caxton Ltd", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Adzuna", "job_id": "YCljVKIBeo8AAAAAAAAAAA==", "job_employment_type": "FULLTIME", "job_title": "Data Analytics Engineer", "job_apply_link": "https://www.adzuna.co.uk/jobs/details/4155156604", "job_apply_is_direct": true, "job_apply_quality_score": 0.4953, "job_description": "We are looking for a skilled and highly motivated Analytics engineer to join our Data & Market intelligence department. As an Analytics Engineer, you will help to build Caxton's Data Foundation. You will work closely with other departments such as Marketing, Sales, Tech and Finance teams to develop, deliver and maintain data-driven solutions and analytics services.\n\nCaxton was born in 2002, an ambitious start-up with one mission: to make payments simple and more transparent. We wanted to make it easier, smarter and cheaper for people to send and spend money across the globe and we\u2019ve stayed true to our word. CXTN, our world-class platform and team helps hundreds of thousands of clients save millions of pounds every year.\n\nOur vision is to shape the future of payments \u2013 with Caxton\u2019s software as a financial service at the core of delivering every payment for individuals to businesses, start-ups, and PLCs.\n\nOur people are at the heart of what we do. This is an exciting position to help drive the business into a new era of data-based decision-making and most importantly help us serve our customers better.\n\nYou\u2019ll join a community, which engages with all members of staff \u2013 including the directors and CEO, thanks to our open-plan office and collaborative, hybrid working.\n\nRequirements\n\nThe primary responsibilities of this position are as follows :\n\u2022 Design & implement Data flow: Create and maintain optimal data Pipeline architecture and re-designing infrastructure for greater scalability\n\u2022 Data ingestion & Data preparation: Automating manual processes, data integrating, managing data resources, optimizing data delivery and ensuring data quality.\n\u2022 Design & develop Analytics Dashboards: Collaborate with data scientists to build reporting and analytical tools.\n\u2022 Monitor and adjust the performance of existing analytics applications.\n\u2022 Gather and identify data-related requirements from stakeholders.\n\nRelevant Qualifications:\n\u2022 Bachelor's degree in computer science, software or computer engineering, or a related field.\n\u2022 2+ years of experience in data engineering and data processing or PhD or Master's degree in a related field.\n\u2022 Expertise working with various technologies (e.g. Python, SQL, Microsoft Power BI)\n\u2022 Knowledge of data mining, and data warehousing concepts, ETL processes, and cloud computing (e.g. Snowflake, Azure etc.)\n\u2022 Excellent collaboration, problem-solving, and communication skills.\n\u2022 Exposure to data science methodologies and project management skills would be nice-to-have.\n\nBenefits\n\u2022 Best in class IT equipment and full support\n\u2022 Great private working space within the Beyond at Aldgate Tower Shared Office with free coffee, Barista and beer on tap\n\u2022 25 days holiday (plus bank holidays)\n\u2022 Annual bonus\n\u2022 Contributory Pension and Life assurance\n\u2022 Vitality Private Health Insurance with family cover\n\u2022 Preferential FX rates for friends and family\n\u2022 + more via \u2018Perks at Work\"\n\nOffice Culture & Environment\n\u2022 Open plan office based in the City of London. Professional and informal culture. Flat hierarchy means direct and regular communication with Directors and the CEO is encouraged\n\u2022 Hybrid working between Home and Office standard\n\u2022 A friendly environment with regular social and inspirational events.", "job_is_remote": false, "job_posted_at_timestamp": 1686915165, "job_posted_at_datetime_utc": "2023-06-16T11:32:45.000Z", "job_city": "London", "job_state": null, "job_country": "GB", "job_latitude": 51.507217, "job_longitude": -0.1275862, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+and+data+analyst+in+uk+and+usa&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+and+data+analyst+in+uk+and+usa&htidocid=YCljVKIBeo8AAAAAAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2023-07-01T23:37:53.000Z", "job_offer_expiration_timestamp": 1688254673, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 24, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {}, "job_job_title": "Engineer", "job_posting_language": "en", "job_onet_soc": "43911100", "job_onet_job_zone": "4"}]}